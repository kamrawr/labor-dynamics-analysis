{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labor Dynamics Analysis: Data Exploration\n",
    "\n",
    "This notebook provides an initial exploration of college enrollment and employment data to understand the relationship between higher education participation and labor market dynamics.\n",
    "\n",
    "## Objectives\n",
    "1. Load and examine college enrollment data\n",
    "2. Load and examine employment/unemployment data\n",
    "3. Perform basic data quality assessment\n",
    "4. Explore temporal trends in both datasets\n",
    "5. Identify potential relationships for deeper analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from data_collection import fetch_enrollment_data, fetch_employment_data, process_and_merge\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Analysis Period: 2000-2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Let's start by collecting enrollment and employment data for our analysis period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analysis period\n",
    "ANALYSIS_YEARS = range(2000, 2025)\n",
    "\n",
    "print(f\"Collecting data for years {ANALYSIS_YEARS.start} to {ANALYSIS_YEARS.stop-1}...\")\n",
    "\n",
    "# Fetch enrollment data (using synthetic data for development)\n",
    "enrollment_data = fetch_enrollment_data(ANALYSIS_YEARS, use_synthetic=True)\n",
    "print(f\"âœ“ Enrollment data collected: {len(enrollment_data)} records\")\n",
    "\n",
    "# Fetch employment data (note: will need BLS API key for real data)\n",
    "try:\n",
    "    employment_data = fetch_employment_data(ANALYSIS_YEARS)\n",
    "    print(f\"âœ“ Employment data collected: {len(employment_data)} records\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Employment data collection failed: {e}\")\n",
    "    print(\"Using synthetic employment data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic employment data for demo\n",
    "    years = list(ANALYSIS_YEARS)\n",
    "    employment_data = pd.DataFrame({\n",
    "        'year': years,\n",
    "        'civilian_labor_force': np.random.normal(160000, 5000, len(years)),\n",
    "        'employment_level': np.random.normal(150000, 5000, len(years)),\n",
    "        'unemployment_rate': np.random.normal(6.0, 2.0, len(years))\n",
    "    })\n",
    "    print(f\"âœ“ Synthetic employment data created: {len(employment_data)} records\")\n",
    "\n",
    "print(\"\\nData collection completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "\n",
    "Let's examine the structure and basic statistics of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrollment data overview\n",
    "print(\"=\" * 50)\n",
    "print(\"ENROLLMENT DATA OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {enrollment_data.shape}\")\n",
    "print(f\"Columns: {list(enrollment_data.columns)}\")\n",
    "print(f\"Data types:\\n{enrollment_data.dtypes}\")\n",
    "print(f\"\\nYear range: {enrollment_data['year'].min()} - {enrollment_data['year'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(enrollment_data.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(enrollment_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment data overview\n",
    "print(\"=\" * 50)\n",
    "print(\"EMPLOYMENT DATA OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {employment_data.shape}\")\n",
    "print(f\"Columns: {list(employment_data.columns)}\")\n",
    "print(f\"Data types:\\n{employment_data.dtypes}\")\n",
    "print(f\"\\nYear range: {employment_data['year'].min()} - {employment_data['year'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(employment_data.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(employment_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n",
    "\n",
    "Check for missing values, outliers, and data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"\\nEnrollment Data Missing Values:\")\n",
    "enrollment_missing = enrollment_data.isnull().sum()\n",
    "print(enrollment_missing[enrollment_missing > 0])\n",
    "\n",
    "print(\"\\nEmployment Data Missing Values:\")\n",
    "employment_missing = employment_data.isnull().sum()\n",
    "print(employment_missing[employment_missing > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows in enrollment data: {enrollment_data.duplicated().sum()}\")\n",
    "print(f\"Duplicate rows in employment data: {employment_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Trends Analysis\n",
    "\n",
    "Visualize trends in enrollment and employment over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive trend plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Labor Dynamics: Enrollment vs Employment Trends (2000-2024)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Total Enrollment Trend\n",
    "if 'total_enrollment' in enrollment_data.columns:\n",
    "    axes[0,0].plot(enrollment_data['year'], enrollment_data['total_enrollment']/1_000_000, \n",
    "                   marker='o', linewidth=2, markersize=4, color='blue')\n",
    "    axes[0,0].set_title('Total College Enrollment', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Year')\n",
    "    axes[0,0].set_ylabel('Enrollment (Millions)')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(enrollment_data['year'], enrollment_data['total_enrollment']/1_000_000, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0,0].plot(enrollment_data['year'], p(enrollment_data['year']), \"--\", alpha=0.7, color='red')\n",
    "\n",
    "# Plot 2: Employment Level Trend\n",
    "if 'employment_level' in employment_data.columns:\n",
    "    axes[0,1].plot(employment_data['year'], employment_data['employment_level']/1_000, \n",
    "                   marker='s', linewidth=2, markersize=4, color='green')\n",
    "    axes[0,1].set_title('Employment Level', fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Year')\n",
    "    axes[0,1].set_ylabel('Employment (Thousands)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Unemployment Rate\n",
    "if 'unemployment_rate' in employment_data.columns:\n",
    "    axes[1,0].plot(employment_data['year'], employment_data['unemployment_rate'], \n",
    "                   marker='^', linewidth=2, markersize=4, color='red')\n",
    "    axes[1,0].set_title('Unemployment Rate', fontweight='bold')\n",
    "    axes[1,0].set_xlabel('Year')\n",
    "    axes[1,0].set_ylabel('Unemployment Rate (%)')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Enrollment Breakdown (if available)\n",
    "if all(col in enrollment_data.columns for col in ['undergraduate', 'graduate']):\n",
    "    axes[1,1].plot(enrollment_data['year'], enrollment_data['undergraduate']/1_000_000, \n",
    "                   marker='o', linewidth=2, label='Undergraduate', alpha=0.8)\n",
    "    axes[1,1].plot(enrollment_data['year'], enrollment_data['graduate']/1_000_000, \n",
    "                   marker='s', linewidth=2, label='Graduate', alpha=0.8)\n",
    "    axes[1,1].set_title('Enrollment by Level', fontweight='bold')\n",
    "    axes[1,1].set_xlabel('Year')\n",
    "    axes[1,1].set_ylabel('Enrollment (Millions)')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Enrollment breakdown\\ndata not available', \n",
    "                   ha='center', va='center', transform=axes[1,1].transAxes, fontsize=12)\n",
    "    axes[1,1].set_title('Enrollment Breakdown', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initial Correlation Analysis\n",
    "\n",
    "Merge the datasets and look for potential relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and merge datasets\n",
    "print(\"Processing and merging datasets...\")\n",
    "merged_data = process_and_merge(enrollment_data, employment_data, save_cache=True)\n",
    "\n",
    "if not merged_data.empty:\n",
    "    print(f\"âœ“ Merged dataset created: {merged_data.shape}\")\n",
    "    print(f\"Columns: {list(merged_data.columns)}\")\n",
    "    \n",
    "    # Display merged data sample\n",
    "    print(\"\\nMerged Data Sample:\")\n",
    "    display(merged_data.head(10))\n",
    "else:\n",
    "    print(\"âš  Failed to merge datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "if not merged_data.empty:\n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = merged_data.select_dtypes(include=[np.number]).columns\n",
    "    correlation_matrix = merged_data[numeric_cols].corr()\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Correlation Matrix: Enrollment vs Employment Metrics', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Highlight key correlations\n",
    "    print(\"\\nKey Correlations (|r| > 0.3):\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Find correlations between enrollment and employment variables\n",
    "    enrollment_cols = [col for col in numeric_cols if 'enrollment' in col]\n",
    "    employment_cols = [col for col in numeric_cols if 'employment' in col or 'unemployment' in col]\n",
    "    \n",
    "    for enroll_col in enrollment_cols:\n",
    "        for employ_col in employment_cols:\n",
    "            if enroll_col != employ_col:\n",
    "                corr_val = correlation_matrix.loc[enroll_col, employ_col]\n",
    "                if abs(corr_val) > 0.3:\n",
    "                    print(f\"{enroll_col} â†” {employ_col}: {corr_val:.3f}\")\n",
    "else:\n",
    "    print(\"Cannot perform correlation analysis - merged dataset is empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Next Steps\n",
    "\n",
    "Summarize initial findings and outline areas for deeper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not enrollment_data.empty:\n",
    "    print(\"\\nðŸ“Š ENROLLMENT DATA INSIGHTS:\")\n",
    "    print(f\"  â€¢ Time period: {enrollment_data['year'].min()} - {enrollment_data['year'].max()}\")\n",
    "    print(f\"  â€¢ Data points: {len(enrollment_data)} years\")\n",
    "    \n",
    "    if 'total_enrollment' in enrollment_data.columns:\n",
    "        total_change = enrollment_data['total_enrollment'].iloc[-1] - enrollment_data['total_enrollment'].iloc[0]\n",
    "        pct_change = (total_change / enrollment_data['total_enrollment'].iloc[0]) * 100\n",
    "        print(f\"  â€¢ Total enrollment change: {total_change:,.0f} ({pct_change:+.1f}%)\")\n",
    "        \n",
    "        avg_annual_growth = ((enrollment_data['total_enrollment'].iloc[-1] / \n",
    "                             enrollment_data['total_enrollment'].iloc[0]) ** \n",
    "                            (1/(len(enrollment_data)-1)) - 1) * 100\n",
    "        print(f\"  â€¢ Average annual growth: {avg_annual_growth:+.2f}%\")\n",
    "\n",
    "if not employment_data.empty:\n",
    "    print(\"\\nðŸ’¼ EMPLOYMENT DATA INSIGHTS:\")\n",
    "    print(f\"  â€¢ Time period: {employment_data['year'].min()} - {employment_data['year'].max()}\")\n",
    "    print(f\"  â€¢ Data points: {len(employment_data)} years\")\n",
    "    \n",
    "    if 'unemployment_rate' in employment_data.columns:\n",
    "        avg_unemployment = employment_data['unemployment_rate'].mean()\n",
    "        min_unemployment = employment_data['unemployment_rate'].min()\n",
    "        max_unemployment = employment_data['unemployment_rate'].max()\n",
    "        print(f\"  â€¢ Average unemployment rate: {avg_unemployment:.1f}%\")\n",
    "        print(f\"  â€¢ Unemployment range: {min_unemployment:.1f}% - {max_unemployment:.1f}%\")\n",
    "\n",
    "if not merged_data.empty:\n",
    "    print(\"\\nðŸ”— RELATIONSHIP INSIGHTS:\")\n",
    "    print(f\"  â€¢ Successfully merged {len(merged_data)} years of data\")\n",
    "    print(f\"  â€¢ {len(correlation_matrix.columns)} metrics available for analysis\")\n",
    "    \n",
    "    # Count significant correlations\n",
    "    strong_correlations = np.sum(np.abs(correlation_matrix.values) > 0.5) - len(correlation_matrix)\n",
    "    moderate_correlations = np.sum((np.abs(correlation_matrix.values) > 0.3) & \n",
    "                                  (np.abs(correlation_matrix.values) <= 0.5))\n",
    "    print(f\"  â€¢ Strong correlations (|r| > 0.5): {strong_correlations//2}\")\n",
    "    print(f\"  â€¢ Moderate correlations (0.3 < |r| â‰¤ 0.5): {moderate_correlations//2}\")\n",
    "\n",
    "print(\"\\nðŸ“‹ NEXT STEPS FOR ANALYSIS:\")\n",
    "print(\"  1. Detailed enrollment trend analysis by demographics and institution type\")\n",
    "print(\"  2. Employment pattern analysis across different economic cycles\")\n",
    "print(\"  3. Regional/geographic analysis of enrollment-employment relationships\")\n",
    "print(\"  4. Time-lagged correlation analysis (enrollment â†’ employment outcomes)\")\n",
    "print(\"  5. Economic event impact analysis (recessions, policy changes)\")\n",
    "print(\"  6. Predictive modeling for future trends\")\n",
    "\n",
    "print(\"\\nâœ… Data exploration completed successfully!\")\n",
    "print(\"   Proceed to notebook 02_enrollment_analysis.ipynb for detailed enrollment analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Export\n",
    "\n",
    "Save cleaned and merged data for use in subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for next notebooks\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save individual cleaned datasets\n",
    "enrollment_data.to_csv(output_dir / 'clean_enrollment_data.csv', index=False)\n",
    "employment_data.to_csv(output_dir / 'clean_employment_data.csv', index=False)\n",
    "\n",
    "if not merged_data.empty:\n",
    "    merged_data.to_csv(output_dir / 'merged_labor_education_data.csv', index=False)\n",
    "    print(f\"âœ“ Saved merged dataset: {len(merged_data)} records\")\n",
    "\n",
    "print(f\"âœ“ Data saved to {output_dir}\")\n",
    "print(\"âœ… Analysis complete - ready for next phase!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}