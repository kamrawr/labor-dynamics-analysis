{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labor Dynamics Analysis: Data Exploration\n",
    "\n",
    "This notebook provides an initial exploration of college enrollment and employment data to understand the relationship between higher education participation and labor market dynamics.\n",
    "\n",
    "## Objectives\n",
    "1. Load and examine college enrollment data\n",
    "2. Load and examine employment/unemployment data\n",
    "3. Perform basic data quality assessment\n",
    "4. Explore temporal trends in both datasets\n",
    "5. Identify potential relationships for deeper analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from data_collection import fetch_enrollment_data, fetch_employment_data, process_and_merge\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Analysis Period: 2000-2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Let's start by collecting enrollment and employment data for our analysis period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analysis period\n",
    "ANALYSIS_YEARS = range(2000, 2025)\n",
    "\n",
    "print(f\"Collecting data for years {ANALYSIS_YEARS.start} to {ANALYSIS_YEARS.stop-1}...\")\n",
    "\n",
    "# Fetch enrollment data (using synthetic data for development)\n",
    "enrollment_data = fetch_enrollment_data(ANALYSIS_YEARS, use_synthetic=True)\n",
    "print(f\"✓ Enrollment data collected: {len(enrollment_data)} records\")\n",
    "\n",
    "# Fetch employment data (note: will need BLS API key for real data)\n",
    "try:\n",
    "    employment_data = fetch_employment_data(ANALYSIS_YEARS)\n",
    "    print(f\"✓ Employment data collected: {len(employment_data)} records\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Employment data collection failed: {e}\")\n",
    "    print(\"Using synthetic employment data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic employment data for demo\n",
    "    years = list(ANALYSIS_YEARS)\n",
    "    employment_data = pd.DataFrame({\n",
    "        'year': years,\n",
    "        'civilian_labor_force': np.random.normal(160000, 5000, len(years)),\n",
    "        'employment_level': np.random.normal(150000, 5000, len(years)),\n",
    "        'unemployment_rate': np.random.normal(6.0, 2.0, len(years))\n",
    "    })\n",
    "    print(f\"✓ Synthetic employment data created: {len(employment_data)} records\")\n",
    "\n",
    "print(\"\\nData collection completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "\n",
    "Let's examine the structure and basic statistics of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrollment data overview\n",
    "print(\"=\" * 50)\n",
    "print(\"ENROLLMENT DATA OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {enrollment_data.shape}\")\n",
    "print(f\"Columns: {list(enrollment_data.columns)}\")\n",
    "print(f\"Data types:\\n{enrollment_data.dtypes}\")\n",
    "print(f\"\\nYear range: {enrollment_data['year'].min()} - {enrollment_data['year'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(enrollment_data.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(enrollment_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment data overview\n",
    "print(\"=\" * 50)\n",
    "print(\"EMPLOYMENT DATA OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {employment_data.shape}\")\n",
    "print(f\"Columns: {list(employment_data.columns)}\")\n",
    "print(f\"Data types:\\n{employment_data.dtypes}\")\n",
    "print(f\"\\nYear range: {employment_data['year'].min()} - {employment_data['year'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(employment_data.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(employment_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n",
    "\n",
    "Check for missing values, outliers, and data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"\\nEnrollment Data Missing Values:\")\n",
    "enrollment_missing = enrollment_data.isnull().sum()\n",
    "print(enrollment_missing[enrollment_missing > 0])\n",
    "\n",
    "print(\"\\nEmployment Data Missing Values:\")\n",
    "employment_missing = employment_data.isnull().sum()\n",
    "print(employment_missing[employment_missing > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows in enrollment data: {enrollment_data.duplicated().sum()}\")\n",
    "print(f\"Duplicate rows in employment data: {employment_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Trends Analysis\n",
    "\n",
    "Visualize trends in enrollment and employment over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive trend plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Labor Dynamics: Enrollment vs Employment Trends (2000-2024)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Total Enrollment Trend\n",
    "if 'total_enrollment' in enrollment_data.columns:\n",
    "    axes[0,0].plot(enrollment_data['year'], enrollment_data['total_enrollment']/1_000_000, \n",
    "                   marker='o', linewidth=2, markersize=4, color='blue')\n",
    "    axes[0,0].set_title('Total College Enrollment', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Year')\n",
    "    axes[0,0].set_ylabel('Enrollment (Millions)')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(enrollment_data['year'], enrollment_data['total_enrollment']/1_000_000, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0,0].plot(enrollment_data['year'], p(enrollment_data['year']), \"--\", alpha=0.7, color='red')\n",
    "\n",
    "# Plot 2: Employment Level Trend\n",
    "if 'employment_level' in employment_data.columns:\n",
    "    axes[0,1].plot(employment_data['year'], employment_data['employment_level']/1_000, \n",
    "                   marker='s', linewidth=2, markersize=4, color='green')\n",
    "    axes[0,1].set_title('Employment Level', fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Year')\n",
    "    axes[0,1].set_ylabel('Employment (Thousands)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Unemployment Rate\n",
    "if 'unemployment_rate' in employment_data.columns:\n",
    "    axes[1,0].plot(employment_data['year'], employment_data['unemployment_rate'], \n",
    "                   marker='^', linewidth=2, markersize=4, color='red')\n",
    "    axes[1,0].set_title('Unemployment Rate', fontweight='bold')\n",
    "    axes[1,0].set_xlabel('Year')\n",
    "    axes[1,0].set_ylabel('Unemployment Rate (%)')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Enrollment Breakdown (if available)\n",
    "if all(col in enrollment_data.columns for col in ['undergraduate', 'graduate']):\n",
    "    axes[1,1].plot(enrollment_data['year'], enrollment_data['undergraduate']/1_000_000, \n",
    "                   marker='o', linewidth=2, label='Undergraduate', alpha=0.8)\n",
    "    axes[1,1].plot(enrollment_data['year'], enrollment_data['graduate']/1_000_000, \n",
    "                   marker='s', linewidth=2, label='Graduate', alpha=0.8)\n",
    "    axes[1,1].set_title('Enrollment by Level', fontweight='bold')\n",
    "    axes[1,1].set_xlabel('Year')\n",
    "    axes[1,1].set_ylabel('Enrollment (Millions)')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Enrollment breakdown\\ndata not available', \n",
    "                   ha='center', va='center', transform=axes[1,1].transAxes, fontsize=12)\n",
    "    axes[1,1].set_title('Enrollment Breakdown', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initial Correlation Analysis\n",
    "\n",
    "Merge the datasets and look for potential relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and merge datasets\n",
    "print(\"Processing and merging datasets...\")\n",
    "merged_data = process_and_merge(enrollment_data, employment_data, save_cache=True)\n",
    "\n",
    "if not merged_data.empty:\n",
    "    print(f\"✓ Merged dataset created: {merged_data.shape}\")\n",
    "    print(f\"Columns: {list(merged_data.columns)}\")\n",
    "    \n",
    "    # Display merged data sample\n",
    "    print(\"\\nMerged Data Sample:\")\n",
    "    display(merged_data.head(10))\n",
    "else:\n",
    "    print(\"⚠ Failed to merge datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "if not merged_data.empty:\n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = merged_data.select_dtypes(include=[np.number]).columns\n",
    "    correlation_matrix = merged_data[numeric_cols].corr()\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Correlation Matrix: Enrollment vs Employment Metrics', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Highlight key correlations\n",
    "    print(\"\\nKey Correlations (|r| > 0.3):\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Find correlations between enrollment and employment variables\n",
    "    enrollment_cols = [col for col in numeric_cols if 'enrollment' in col]\n",
    "    employment_cols = [col for col in numeric_cols if 'employment' in col or 'unemployment' in col]\n",
    "    \n",
    "    for enroll_col in enrollment_cols:\n",
    "        for employ_col in employment_cols:\n",
    "            if enroll_col != employ_col:\n",
    "                corr_val = correlation_matrix.loc[enroll_col, employ_col]\n",
    "                if abs(corr_val) > 0.3:\n",
    "                    print(f\"{enroll_col} ↔ {employ_col}: {corr_val:.3f}\")\n",
    "else:\n",
    "    print(\"Cannot perform correlation analysis - merged dataset is empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Next Steps\n",
    "\n",
    "Summarize initial findings and outline areas for deeper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not enrollment_data.empty:\n",
    "    print(\"\\n📊 ENROLLMENT DATA INSIGHTS:\")\n",
    "    print(f\"  • Time period: {enrollment_data['year'].min()} - {enrollment_data['year'].max()}\")\n",
    "    print(f\"  • Data points: {len(enrollment_data)} years\")\n",
    "    \n",
    "    if 'total_enrollment' in enrollment_data.columns:\n",
    "        total_change = enrollment_data['total_enrollment'].iloc[-1] - enrollment_data['total_enrollment'].iloc[0]\n",
    "        pct_change = (total_change / enrollment_data['total_enrollment'].iloc[0]) * 100\n",
    "        print(f\"  • Total enrollment change: {total_change:,.0f} ({pct_change:+.1f}%)\")\n",
    "        \n",
    "        avg_annual_growth = ((enrollment_data['total_enrollment'].iloc[-1] / \n",
    "                             enrollment_data['total_enrollment'].iloc[0]) ** \n",
    "                            (1/(len(enrollment_data)-1)) - 1) * 100\n",
    "        print(f\"  • Average annual growth: {avg_annual_growth:+.2f}%\")\n",
    "\n",
    "if not employment_data.empty:\n",
    "    print(\"\\n💼 EMPLOYMENT DATA INSIGHTS:\")\n",
    "    print(f\"  • Time period: {employment_data['year'].min()} - {employment_data['year'].max()}\")\n",
    "    print(f\"  • Data points: {len(employment_data)} years\")\n",
    "    \n",
    "    if 'unemployment_rate' in employment_data.columns:\n",
    "        avg_unemployment = employment_data['unemployment_rate'].mean()\n",
    "        min_unemployment = employment_data['unemployment_rate'].min()\n",
    "        max_unemployment = employment_data['unemployment_rate'].max()\n",
    "        print(f\"  • Average unemployment rate: {avg_unemployment:.1f}%\")\n",
    "        print(f\"  • Unemployment range: {min_unemployment:.1f}% - {max_unemployment:.1f}%\")\n",
    "\n",
    "if not merged_data.empty:\n",
    "    print(\"\\n🔗 RELATIONSHIP INSIGHTS:\")\n",
    "    print(f\"  • Successfully merged {len(merged_data)} years of data\")\n",
    "    print(f\"  • {len(correlation_matrix.columns)} metrics available for analysis\")\n",
    "    \n",
    "    # Count significant correlations\n",
    "    strong_correlations = np.sum(np.abs(correlation_matrix.values) > 0.5) - len(correlation_matrix)\n",
    "    moderate_correlations = np.sum((np.abs(correlation_matrix.values) > 0.3) & \n",
    "                                  (np.abs(correlation_matrix.values) <= 0.5))\n",
    "    print(f\"  • Strong correlations (|r| > 0.5): {strong_correlations//2}\")\n",
    "    print(f\"  • Moderate correlations (0.3 < |r| ≤ 0.5): {moderate_correlations//2}\")\n",
    "\n",
    "print(\"\\n📋 NEXT STEPS FOR ANALYSIS:\")\n",
    "print(\"  1. Detailed enrollment trend analysis by demographics and institution type\")\n",
    "print(\"  2. Employment pattern analysis across different economic cycles\")\n",
    "print(\"  3. Regional/geographic analysis of enrollment-employment relationships\")\n",
    "print(\"  4. Time-lagged correlation analysis (enrollment → employment outcomes)\")\n",
    "print(\"  5. Economic event impact analysis (recessions, policy changes)\")\n",
    "print(\"  6. Predictive modeling for future trends\")\n",
    "\n",
    "print(\"\\n✅ Data exploration completed successfully!\")\n",
    "print(\"   Proceed to notebook 02_enrollment_analysis.ipynb for detailed enrollment analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Export\n",
    "\n",
    "Save cleaned and merged data for use in subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for next notebooks\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save individual cleaned datasets\n",
    "enrollment_data.to_csv(output_dir / 'clean_enrollment_data.csv', index=False)\n",
    "employment_data.to_csv(output_dir / 'clean_employment_data.csv', index=False)\n",
    "\n",
    "if not merged_data.empty:\n",
    "    merged_data.to_csv(output_dir / 'merged_labor_education_data.csv', index=False)\n",
    "    print(f\"✓ Saved merged dataset: {len(merged_data)} records\")\n",
    "\n",
    "print(f\"✓ Data saved to {output_dir}\")\n",
    "print(\"✅ Analysis complete - ready for next phase!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}